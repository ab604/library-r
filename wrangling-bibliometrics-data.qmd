# Wrangling bibliometrics data {#sec-wrangling-bibliometrics-data}

**WORK IN PROGRESS**

::: {#bibliometrics-summary .callout-important .unnumbered title="Summary" appearance="simple" icon="false"}
The bibliometrics team have a spreadsheet detailing published journal articles from which they would like to understand, *"Which UoS department is affiliated to each article?"*

Here we go through the process of wrangling the data to answer this question and produce some summary statistics.
:::

It's time to apply our knowledge to some bibliometrics data.

```{r}
#| message: false
#| warning: false
#| label: load-libraries
library(tidyverse)
library(readxl)
library(janitor)
```

## Describing the problem

I'll attempt to describe the problem as I understand it, and then break it down into parts that correspond with @sec-getting-started , @sec-data-wrangling-i and @sec-data-wrangling-ii.

Here's an excerpt from an email Kate sent me on 2023-11-21:

> \[A spreadsheet\] is produced from a fortnightly check... for REF and Funder Compliance... the Export Control Team periodically asks us for information about particular staff/institutions/countries and...trying to search in the Affiliations can be very time consuming...

From what I can see, the overarching problem is this:

:::{.callout-note appearance="simple" icon="false"}
1. There are three data sources: Scopus, Web of Science and Pure, from which tables about publications are regularly downloaded.

All three tables contain DOIs for the publications, but only Scopus has the UoS department affiliations, and Pure contains the Open Access compliance information

2. The data contained in these three tables needs to be joined, and then joined to other data.
3. The final output is a table indicating the open access status, funding body compliance status and University department affiliation for each publication.
:::

I'm not going to be able to cover every step, For some of these steps we need to create our own tables of data e.g a table of department codes or open access codes, as well as download pre-existing data. 

I downloaded some data as a `csv` file from [Scopus Advanced Search](https://www.scopus.com/search/form.uri?display=advanced) to generate a report for 31 days prior to 2024-03-13 using the following query string:

```         
AF-ID("University of Southampton" 60025225) AND PUBYEAR > 2017 AND PUBYEAR < 2025 AND ( LIMIT-TO ( DOCTYPE,"ar" ) OR LIMIT-TO ( DOCTYPE,"re" ) OR LIMIT-TO ( DOCTYPE,"cp" ) OR LIMIT-TO ( DOCTYPE,"ed" ) OR LIMIT-TO ( DOCTYPE,"le" ) ) AND RECENT(31)
```

I'll read it in directly from the repository for this book, and use `glimpse()` to look at the contents. It has 483 rows and 20 columns, each row comprises a set of observations for a single publication as per @fig-tidy-data, the title of each publication is in the `Title` column.

```{r}
#| label: load-data
#| message: false
# Load the Pure csv file
pure_dat <- read_csv("https://github.com/ab604/library-r/raw/main/data/pure-2024-03-26.csv")
# Load the scopus csv file
scopus_dat <- read_csv("https://github.com/ab604/library-r/raw/main/data/scopus-2024-03-13.csv")
# Load the Web of science tsv file
wos_dat <- read_tsv("https://github.com/ab604/library-r/raw/main/data/web-of-science-2024-03-26.tsv")

# Look at the contents
glimpse(pure_dat)
glimpse(scopus_dat)
glimpse(wos_dat)
```

```{r}
wos_mut <- wos_dat |> 
  mutate(department = str_extract(C1,"(?<=Southampton Univ,|Univ Southampton,|Univ Hosp Southampton NHS Fdn Trust,)(.*?)(?=, )"))

wos_mut |> 
  select(C1, department) |> 
  view()
```


So let's assume the question here is:

> "Which University of Southampton Department(s) are affiliated with each publication?"

The departments are in the `Affiliations` column. Using two more `dplyr` verbs, `slice()` and `pull()`, let's look at the first four values (@lst-slice-affiliation).

::: {.callout-note appearance="simple" icon="false"}
Note how I've used an integer vector `1:4` as the argument to `slice()` to indicate I want rows 1 to 4, and then the column variable of interest as the argument for `pull()` to pull out the values for the `Affiliations` in rows 1 to 4.
:::

This yields a character vector with four values and I can immediately see that `Affiliations` does contain not a single tidy value in each cell, it's a **messy** value with multiple values separated by semi-colons.

```{r}
#| lst-label: lst-slice-affiliation
#| lst-cap: Slice and pull the first four Affiliation values 
scopus_dat |>         
  slice(1:4) |>       
  pull(Affiliations)  
```

To be tidy, each semi-colon separated value should be in their own column. So we need to tidy the data (@sec-tidy-data, @fig-tidy-data ).

## Tidying the Scopus data

Let's break the problem down:

1.  First let's separate the multiple affiliations that are in a single column into multiple columns, one for each affiliation. This is in keeping with tidy rule that each value should have it's own cell.

We can use `tidyr` package function [`separate_wider_delim()`](https://tidyr.tidyverse.org/reference/separate_wider_delim.html).

`separate_wider_delim()` takes three necessary arguments, and has several other optional arguments. The necessary ones are a data frame, here that's `scopus_dat`. `cols` the column(s) we are separating, here that's `Affiliations` and `delim` is a string we using as a delimiter to split the values on which as we saw is going to be `;`.

As this is going to create new column variables, these need names too and here I provide the string for underscore `"_"` to `names_sep` and each new variable will have an underscore and numerical suffix called `Affiliations_1`, `Affiliations_2` etc.

The final argument we'll use is `too_few` and we'll use `"align_start"` as the value. This means that our departments will first be put in `Affiliations_1` and adds missing values columns `NA` in any columns where a row runs out of departments. This ensures all rows have the same number of columns regardless of how many values were in the original Affiliations column. The total number of Affiliation columns will be determined by the article with the most Affiliation values. 

Hence the table will get wider as new columns are created!

I'll assign the output to a new data frame object `scopus_dat_wide`.

```{r}
#| lst-label: lst-sep-wide-delim
#| lst-cap: Separating the Affiliation values in `scopus_dat` into individual columns using `separate_wider_delim()`. 
scopus_dat_wide <- scopus_dat |> 
  separate_wider_delim(cols = Affiliations, 
                       delim = ";", 
                       names_sep = "_", 
                       too_few = "align_start")
```

I'll leave it for you to examine, but you should see we have 311 Affiliation variables now, many of the contain missing values `NA`. We still have 483 rows, but 330 variables in total.

```{r}
#| eval: false
glimpse(scopus_dat_wide) 
```

2. How do we get rid of all those missing values? We can fix that by changing the shape of the data to long with `pivot_longer()` and dropping any `Affiliation` values that are `NA`.

Concretely, we have 311 Affiliation columns, if we pivot the table such that those column names become values in rows, the values from those columns fill a new single column variable, here `Department`, and we create a long table (with lots of duplicated information). And we can simply drop any row where the value of `Department` is `NA`.

As we have to say which columns we want to take the values from to fill `Department` and all our columns of interest begin with `Affliation_`, we can use the handy `dpylr` select function [`starts_with()`](https://dplyr.tidyverse.org/reference/select.html) to help us.

The name of each `Affiliation_` column will be transformed to values in a column I'm going to call `Affiliation_No`.

This yields a table with 3722 rows and 21 columns, one more column than we started with in the original `scopus_dat` table.

```{r}
#| lst-label: lst-scopus-pivot-long
#| lst-cap: Separating the Affiliation values in `scopus_dat` into individual columns using `separate_wider_delim()`. 

scopus_dat_long <- scopus_dat_wide |> 
  pivot_longer(starts_with("Affiliations_"),
               names_to = "Affiliation_No", 
               values_to = "Department", 
               values_drop_na = TRUE)
```

3. But we're only interested in the University of Southampton affiliations, so many of these rows aren't of use to us.

```{r}
#glimpse(scopus_dat_long)

scopus_dat_long_soton <- scopus_dat_long |> 
  filter(str_detect(Department,"Southampton"))

#scopus_dat_long_other <-  scopus_dat_long |> 
 # filter(!str_detect(Department,"Southampton"))
```
## Web of science

`https://www.webofscience.com/wos/woscc/summary/1d7d2706-f966-4c7c-8cbd-85de6e118dc2-d8d761f7/relevance/1`

```{r}
dat_join <- scopus_dat_long_soton |> left_join(wos_dat, by = "DOI")
```


```{r}
#| message: false
departments <- read_csv("https://github.com/ab604/library-r/raw/main/data/faculty-and-department-codes-2024-03-18.csv")

dept_names <- departments |> pull(department_name) |> glue::glue_collapse(sep = "|")

glimpse(dept_names)

soton_depts <- scopus_dat_long_soton |> 
  mutate(department_name = str_extract(Department,dept_names))
```
