# Wrangling bibliometrics data {#sec-wrangling-bibliometrics-data}

**WORK IN PROGRESS**

::: {#bibliometrics-summary .callout-important .unnumbered title="Summary" appearance="simple" icon="false"}
The bibliometrics team have a spreadsheet detailing published journal articles from which they would like to understand, *"Which UoS department is affiliated to each article?"*

Here we go through the process of wrangling the data to answer this question and produce some summary statistics.
:::

It's time to apply our knowledge to some bibliometrics data.

```{r}
#| message: false
#| warning: false
#| label: load-libraries
library(tidyverse)
library(openxlsx)
library(janitor)
```

## Describing the problem

I'll attempt to describe the problem as I understand it, and then break it down into parts that correspond with @sec-getting-started , @sec-data-wrangling-i and @sec-data-wrangling-ii.

Here's an excerpt from an email Kate sent me on 2023-11-21:

> \[A spreadsheet\] is produced from a fortnightly check... for REF and Funder Compliance... the Export Control Team periodically asks us for information about particular staff/institutions/countries and...trying to search in the Affiliations can be very time consuming...

I downloaded some data as a `csv` file from [Scopus Advanced Search](https://www.scopus.com/search/form.uri?display=advanced) to generate a report for 31 days prior to 2024-03-13 using the following query string:

```         
AF-ID("University of Southampton" 60025225) AND PUBYEAR > 2017 AND PUBYEAR < 2025 AND ( LIMIT-TO ( DOCTYPE,"ar" ) OR LIMIT-TO ( DOCTYPE,"re" ) OR LIMIT-TO ( DOCTYPE,"cp" ) OR LIMIT-TO ( DOCTYPE,"ed" ) OR LIMIT-TO ( DOCTYPE,"le" ) ) AND RECENT(31)
```

I'll read it in directly from the repository for this book, and use `glimpse()` to look at the contents. It has 483 rows and 20 columns, each row comprises a set of observations for a single publication as per @fig-tidy-data, the title of each publication is in the `Title` column.

```{r}
#| label: load-scopus
#| message: false
# Load the scopus csv file
scopus_dat <- read_csv("https://github.com/ab604/library-r/raw/main/data/scopus-2024-03-13.csv")
# Look at the contents
glimpse(scopus_dat)
```

So let's assume the question here is:

> "Which University of Southampton Department(s) are affiliated with each publication?"

The departments are in the `Affiliations` column. Using two more `dplyr` verbs, `slice()` and `pull()`, let's look at the first four values (@lst-slice-affiliation).

::: {.callout-note appearance="simple" icon="false"}
Note how I've used an integer vector `1:4` as the argument to `slice()` to indicate I want rows 1 to 4, and then the column variable of interest as the argument for `pull()` to pull out the values for the `Affiliations` in rows 1 to 4.
:::

This yields a character vector with four values and I can immediately see that `Affiliations` does contain not a single tidy value in each cell, it's a **messy** value with multiple values separated by semi-colons.

```{r}
#| lst-label: lst-slice-affiliation
#| lst-cap: Slice and pull the first four Affiliation values 
scopus_dat |>         
  slice(1:4) |>       
  pull(Affiliations)  
```

To be tidy, each semi-colon separated value should be in their own column.

## Tidying data

In this section we're going to do some more complicated transformations. Let's remind ourselves of the definition of tidy data:

1.  Each variable must have its own column.

2.  Each observation must have its own row.

3.  Each value must have its own cell.

This can come in two forms: **long** or **wide**

We'll start with a table of published articles where each row is a set of observations about each article.

*What makes it untidy?*

It's untidy because here we are interested in the University of Southampton (UoS) affiliations associated with each article. Here, all the individual affiliations for all the institutions affiliated with each paper are combined in a single column rather than their own columns. Therefore the values for each affiliation aren't in their own cells.

Hence for the purposes of the question we wish to pose, *"Which UoS department is affiliated to each article?"* the table is untidy in terms of rules 1 and 3.

### Our workflow

Let's consider the steps we need to take to arrive at a table which is tidy and contains the values for each UoS affiliation for each published article:

1.  Import the table, check it and repair if necessary.
2.  Seperate the affiliations into a new column (variable) for each affiliation associated with each article.

The articles don't all have the same number of affiliations, so we will have lots of columns with only a few values in. In other words a wide table (lots of columns) but sparsely populated. What we want is a table that has only the UoS affiliation observations.

What is our usual trick for obtaining only the observations of interest?

We `filter` the rows. But hang on, we can't do that unless we have the each affiliation in a row, rather spread across lots of columns. So what do?

Transforming a table so that columns become rows, or rows become columns is called ***pivoting***. Here, having separated the affiliations and created a wide table with a variable for each affiliation we want to pivot from wide-to-long.

When we pivot wide-to-long, the column names become a new set of observations in a new variable, and the values from each column become another set of observations in a new variable. Everything else is duplicated and hence we end up with lots of rows.

3.  Using `pivot_long` we create a table on which we can filter the rows for the UoS affiliations.

For some articles there may be multiple UoS affiliations, so we may wish to pivot long-to-wide to create a final tidy table with a single row for each article, but columns for each UoS affiliation.

### Importing

Let's start with a small data set called `OA-compliance-subset-2023-11-29.xlsx` from the repository

```{r}
#| label: import-data
# Use the read.xlsx to download and load the excel file into object dat
dat <- read.xlsx("https://github.com/ab604/library-r/raw/main/data/OA-compliance-subset-2023-11-29.xlsx")
```

Use the `glimpse()` function from `dplyr` to take a peak at this data:

1.  We can see that the table has 20 rows with 35 columns of variables.
2.  Looking at the data types, we can see the import function parsed two types of data: `<chr>` character, meaning strings of text and `<dbl>` double, meaning numerical data. However, looking at the variable names, some are dates and haven't been identified automatically.
3.  There are lots of `NA` s, which are missing values. This may or may not matter.

```{r}
#| label: glimpse-data
glimpse(dat)
```

### Let's fix the dates

We'll make a new object called `dat_repaired` and use the `mutate` function from `dpylr` along with `convert_to_date` in the `janitor` package to convert the number values into dates.

Then we'll take a look with the glimpse function and we can see these look like dates in the year-month-day format and are identified as `<date>` data types.

```{r}
#| label: fix-dates
dat_repaired <- dat |> mutate(Report.Date = convert_to_date(Report.Date),
                              Accepted.Date = convert_to_date(Accepted.Date),
                              Epublication.Date = convert_to_date(Epublication.Date))
glimpse(dat_repaired)
```

```{r}
dat_repaired |> select(Affiliations) |> slice(1:2)
```
