# Wrangling bibliometrics data

::: {#bibliometrics-summary .callout-important .unnumbered title="Summary" appearance="simple" icon="false"}
The bibliometrics team have a spreadsheet detailing published journal articles from which they would like to understand, *"Which UoS department is affiliated to each article?"*

Here we go through the process of wrangling the data to answer this question and produce some summary statistics.
:::

It's time to apply our knowledge to some bibliometrics data.

```{r}
#| message: false
#| warning: false
#| label: load-libraries
library(tidyverse)
library(openxlsx)
library(janitor)
```

## Tidying data

In this section we're going to do some more complicated transformations. Let's remind ourselves of the definition of tidy data:

1.  Each variable must have its own column.

2.  Each observation must have its own row.

3.  Each value must have its own cell.

This can come in two forms: **long** or **wide**

We'll start with a table of published articles where each row is a set of observations about each article.

*What makes it untidy?*

It's untidy because here we are interested in the University of Southampton (UoS) affiliations associated with each article. Here, all the individual affiliations for all the institutions affiliated with each paper are combined in a single column rather than their own columns. Therefore the values for each affiliation aren't in their own cells.

Hence for the purposes of the question we wish to pose, *"Which UoS department is affiliated to each article?"* the table is untidy in terms of rules 1 and 3.

### Our workflow

Let's consider the steps we need to take to arrive at a table which is tidy and contains the values for each UoS affiliation for each published article:

1.  Import the table, check it and repair if necessary.
2.  Seperate the affiliations into a new column (variable) for each affiliation associated with each article.

The articles don't all have the same number of affiliations, so we will have lots of columns with only a few values in. In other words a wide table (lots of columns) but sparsely populated. What we want is a table that has only the UoS affiliation observations.

What is our usual trick for obtaining only the observations of interest?

We `filter` the rows. But hang on, we can't do that unless we have the each affiliation in a row, rather spread across lots of columns. So what do?

Transforming a table so that columns become rows, or rows become columns is called ***pivoting***. Here, having separated the affiliations and created a wide table with a variable for each affiliation we want to pivot from wide-to-long.

When we pivot wide-to-long, the column names become a new set of observations in a new variable, and the values from each column become another set of observations in a new variable. Everything else is duplicated and hence we end up with lots of rows.

3.  Using `pivot_long` we create a table on which we can filter the rows for the UoS affiliations.

For some articles there may be multiple UoS affiliations, so we may wish to pivot long-to-wide to create a final tidy table with a single row for each article, but columns for each UoS affiliation.

### Importing

Let's start with a small data set called `OA-compliance-subset-2023-11-29.xlsx` from the repository

```{r}
#| label: import-data
# Use the read.xlsx to download and load the excel file into object dat
dat <- read.xlsx("https://github.com/ab604/library-r/raw/main/data/OA-compliance-subset-2023-11-29.xlsx")
```

Use the `glimpse()` function from `dplyr` to take a peak at this data:

1.  We can see that the table has 20 rows with 35 columns of variables.
2.  Looking at the data types, we can see the import function parsed two types of data: `<chr>` character, meaning strings of text and `<dbl>` double, meaning numerical data. However, looking at the variable names, some are dates and haven't been identified automatically.
3.  There are lots of `NA` s, which are missing values. This may or may not matter.

```{r}
#| label: glimpse-data
glimpse(dat)
```

### Let's fix the dates

We'll make a new object called `dat_repaired` and use the `mutate` function from `dpylr` along with `convert_to_date` in the `janitor` package to convert the number values into dates.

Then we'll take a look with the glimpse function and we can see these look like dates in the year-month-day format and are identified as `<date>` data types.

```{r}
#| label: fix-dates
dat_repaired <- dat |> mutate(Report.Date = convert_to_date(Report.Date),
                              Accepted.Date = convert_to_date(Accepted.Date),
                              Epublication.Date = convert_to_date(Epublication.Date))
glimpse(dat_repaired)
```

```{r}
dat_repaired |> select(Affiliations) |> slice(1:2)
```
